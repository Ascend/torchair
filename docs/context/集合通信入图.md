# 集合通信入图

## 功能简介

集合通信入图能够避免断图，并拥有更大的成图范围，从而获得更大的资源调度与融合收益，同时在整图层面实现通信与计算并行优化。

原生PyTorch社区对集合通信算子入图的支持度尚不完善，功能正在持续增强中。TorchAir针对这一现状，采用如下方案增强这块入图能力：

-   **PyTorch 2.1版本**：通过Monkey Patch方式接入Ascend IR计算图，解决原生集合通信算子不支持入图的问题。入图方法参见[使用方法（PyTorch 2.1版本）](#sec1)。
-   **PyTorch 2.6及以上版本**：TorchAir提供的NPU图编译后端实现了集合通信算子的Ascend Converter，调用torch.compile时，默认已支持集合通信算子入图。入图方法参见[使用方法（≥PyTorch 2.6版本）](#sec2)。

目前支持入图的集合通信API如下表所示，请根据实际业务需求按需调用。注意，集合通信算子入图的前提是PyTorch脚本中所有算子均能正常以Eager模式运行。

**表 1**  集合通信API入图支持情况


| PyTorch集合通信API | 支持情况 |
| --- | --- |
| torch.distributed.all_gather | √ |
| torch.distributed.all_gather_into_tensor | √ |
| torch.distributed.all_reduce | √ |
| torch.distributed.all_to_all | √ |
| torch.distributed.all_to_all_single | √ |
| torch.distributed.broadcast | √ |
| torch.distributed.reduce_scatter_tensor | √ |
| torch_npu.distributed.all_gather_into_tensor_uneven | √ |
| torch_npu.distributed.reduce_scatter_tensor_uneven | √ |
| torch.distributed.send | ≥PyTorch 2.6 |
| torch.distributed.recv | ≥PyTorch 2.6 |

torch_npu前缀接口详细介绍请参考《Ascend Extension for PyTorch 自定义API参考》，其余均为PyTorch原生接口。

> **说明：**
>
> - torch.distributed.send和torch.distributed.recv需要配套使用，且dynamic=True的场景，不同的shape会对应不同的FX graph。
> - max-autotune模式下，torch.distributed.send和torch.distributed.recv不传入group参数时需要有默认通信组（所有节点都有send/recv或者提前建好全局默认通信域），传入group参数时应当只包含参与通信的节点；当图中存在多个torch.distributed.send、torch.distributed.recv时，需要设置图遍历顺序为**StableRDFS**（稳定拓扑序策略）。

## 使用方法（PyTorch 2.1版本）<a name="sec1"></a>

> **说明：** 
>分布式场景下，第三方框架（如DeepSpeed）对原生AllReduce API的封装使其无法入图，TorchAir可同时Patch框架中的AllReduce封装函数，以解决入图问题。

-   **方案1**：patch\_for\_hcom补丁包

    假设推理脚本test.py定义如下，在调用torch.compile前**显式调用torchair.patch\_for\_hcom\(\)**即可实现集合通信入图。

    ```python
    import os
    import torch
    import torch_npu
    import torchair
    from torchair.configs.compiler_config import CompilerConfig
    
    # 导入patch包
    torchair.patch_for_hcom()
    class AllReduceSingleGroup(torch.nn.Module):
        def __init__(self):
            super().__init__()
        def forward(self, x, y):
            x = x + y
            torch.distributed.all_reduce(x, op=torch.distributed.ReduceOp.SUM)
            return x
    
    def example(rank, world_size):
        torch.npu.set_device(rank)
        torch.distributed.init_process_group("hccl", rank=rank, world_size=world_size)
        x = torch.ones([2, 2], dtype=torch.int32).to("npu:"+str(rank))
        y = torch.ones([2, 2], dtype=torch.int32).to("npu:"+str(rank))
        config = CompilerConfig()
        npu_backend = torchair.get_npu_backend(compiler_config=config)
        model = torch.compile(AllReduceSingleGroup().to("npu:"+str(rank)), backend=npu_backend, dynamic=False)
        out = torch.ones([2, 2], dtype=torch.int32).npu() * 2 * world_size
        ret = model(x, y)
        assert out.equal(ret)
        torch.distributed.destroy_process_group()
    
    def mp():
        world_size = 2
        torch.multiprocessing.spawn(example, args=(world_size, ), nprocs=world_size, join=True)
    
    if __name__ == '__main__':
        os.environ["MASTER_ADDR"] = "localhost"
        os.environ["MASTER_PORT"] = "29506"    
        mp()
    ```

-   **方案2**（废弃）：patch\_for\_hcom\_allreduce补丁包

    > **说明：** 方案2在Ascend Extension for PyTorch的6.0.RC3版本及后续版本**不再演进**，未来会废弃，建议使用方案1。
    
    推理脚本中导入patch\_for\_hcom\_allreduce包，该包将PyTorch原生torch.distributed.allreduce API替换成torch.distributed.\_functional\_collectives.all\_reduce算子，以实现入图。
    
    ```python
    # 导入patch包
    import torch_npu 
    import torchair.ge_concrete_graph.ge_converter.experimental.patch_for_hcom_allreduce
    ```

## 使用方法（≥PyTorch 2.6版本）<a name="sec2"></a>

无需修改PyTorch脚本，直接调用torch.compile，NPU图编译后端npu\_backend默认集成了集合通信算子入图能力。

```python
import torch
import torch_npu
import torchair
config = torchair.CompilerConfig()
npu_backend = torchair.get_npu_backend(compiler_config=config)
.........
# 多卡模型调用compile，后端提供集合通信入图能力
model = torch.compile(model, backend=npu_backend)
```

