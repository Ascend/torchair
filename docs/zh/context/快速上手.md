# 快速上手

本章提供PyTorch图模式配置的快速上手样例，仅供参考。请根据需要配置图优化和定位调试等功能，详细介绍可参考后续章节。

需要注意的是：

-   使能图模式前，请将模型迁移至昇腾NPU上，**确保模型已在单算子模式（Eager）下正确执行**，具体请参考[《PyTorch 训练模型迁移调优指南》](https://www.hiascend.com/document/redirect/canncommercial-ptmigr)的“模型脚本迁移”章节。
-   脚本中必须先**import torch\_npu**，再**import torchair**才能正常使用。

## 示例说明

TorchAir图模式配置示例如下，仅供参考，请根据实际情况修改自定义的脚本。

```python
# 导包（必须先导torch_npu再导torchair）
import torch
import torch_npu
import torchair

# Patch方式实现集合通信入图（可选）
from torchair import patch_for_hcom
patch_for_hcom()

# 自定义Model
class Model(torch.nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, x, y):
        return torch.add(x, y)
model = Model().npu()

# 配置图模式config
config = torchair.CompilerConfig()
# 配置图执行模式，默认max-autotune
# config.mode = "reduce-overhead"
npu_backend = torchair.get_npu_backend(compiler_config=config)
# 基于NPU backend进行compile
opt_model = torch.compile(model, backend=npu_backend)

# 执行编译后的Model
x = torch.randn(2, 2).npu()
y = torch.randn(2, 2).npu()
opt_model(x, y)
```

## torch.compile

torch.compile为PyTorch原生接口，官网介绍参见[LINK](https://pytorch.org/docs/stable/generated/torch.compile.html#torch-compile)，接口原型如下：

```python
torch.compile(model=None, *, fullgraph=False, dynamic=None, backend='inductor', mode=None, options=None, disable=False)
```

TorchAir图模式通过[torchair.get\_npu\_backend](get_npu_backend.md)接口获取**NPU编译后端**npu\_backend，并将其作为**backend入参**实现昇腾NPU图模式计算。此时TorchAir图模式场景下torch.compile参数的配置说明参见下表。

**表 1**  图模式编译接口说明 <a name="table1"></a>

<table><thead>
  <tr>
    <th>参数名</th>
    <th>说明</th>
    <th>备注</th>
  </tr></thead>
<tbody>
  <tr>
    <td>model</td>
    <td>必选参数。入图部分的模型或者函数。</td>
    <td>-</td>
  </tr>
  <tr>
    <td>fullgraph</td>
    <td>可选参数，bool类型。是否捕获整图进行优化。<br>
     <li>False（缺省值）：非整图优化。</li>
     <li>True：捕获整图优化。</li>
    </td>
    <td rowspan="2">参数含义与原生PyTorch compile接口一致，单击<a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch-compile">LINK</a>获取官网介绍。</td>
  </tr>
  <tr>
    <td>dynamic</td>
    <td>可选参数，bool类型或None。是否启用动态Shape追踪。<br>
     <li>None（缺省值）：自动检测是否启用动态Shape追踪。</li>
     <li>False：不启用动态Shape追踪。</li>
     <li>True：启用动态Shape追踪。</li>
    </td>
  </tr>
  <tr>
    <td>backend</td>
    <td>必选参数，后端选择，缺省值为"inductor"。<br>
    如需使用TorchAir提供的后端，需通过<a href="get_npu_backend.md">torchair.get_npu_backend</a>接口获取并显式传入。 </td>
    <td>通过compiler_config参数配置图模式功能，支持的功能参见<a href="#table2">表2</a>，定义在<a href="CompilerConfig类.md">CompilerConfig类</a>中。
    </td>
  </tr>
 <tr>
    <td>mode</td>
    <td>开销模式，内存开销模式选择，缺省值为None。昇腾NPU暂不支持。</td>
    <td>-</td>
  </tr>
 <tr>
    <td>options</td>
    <td>优化选项，缺省值为None。昇腾NPU暂不支持。</td>
    <td>-</td>
  </tr>
 <tr>
    <td>disable</td>
    <td>可选参数，bool类型。是否关闭torch.compile能力。<br>
     <li>False（缺省值）：开启torch.compile能力。</li>
     <li>True：关闭torch.compile能力，采用单算子模式。</li>
    </td>
     <td>参数含义与原生PyTorch compile接口一致，单击<a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch-compile">LINK</a>获取官网介绍。 </td>
  </tr>
</tbody>
</table>
**表 2**  CompilerConfig功能项<a name="table2"></a>

| 功能项 | 说明 |
| --- | --- |
| debug | 配置debug调试类功能，配置形式为config.debug.xxx。 |
| export | 配置离线导图相关功能，配置形式为config.export.xxx。 |
| dump_config | 配置图模式下数据dump功能，配置形式为config.dump_config.xxx。 |
| fusion_config | 配置图融合相关功能，配置形式为config.fusion_config.xxx。 |
| experimental_config | 配置各种试验功能，配置形式为config.experimental_config.xxx。 |
| inference_config | 配置推理场景相关功能，配置形式为config.inference_config.xxx。 |
| ge_config | 配置Ascend IR图相关功能，配置形式为config.ge_config.xxx。 |
| aclgraph_config | 配置aclgraph相关功能，配置形式为config.aclgraph_config.xxx。 |
| mode | 配置图模式的调度方式，配置形式为config.mode.xxx。 |
