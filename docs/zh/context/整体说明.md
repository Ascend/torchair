# 整体说明

TorchAir是为Ascend Extension for PyTorch提供图模式能力的扩展库，支持用户使用PyTorch在昇腾设备上进行图模式推理。本章详细介绍了TorchAir框架提供的Python API，具体参见下表。

**表 1**  接口列表

<table><thead>
  <tr>
    <th>分类</th>
    <th>接口名</th>
    <th>说明</th>
  </tr></thead>
<tbody>
  <tr>
    <td rowspan="8">torchair</td>
    <td><a href="CompilerConfig类.md">CompilerConfig类</a></td>
    <td>该类用于构造传入torch.compiler backend的配置。 </td>
  </tr>
  <tr>
    <td><a href="dynamo_export.md">dynamo_export</a></td>
    <td>用于导出由TorchAir生成的离线图（air格式）。 </td>
  </tr>
  <tr>
    <td><a href="get_compiler.md">get_compiler</a></td>
    <td>获取能够在NPU上运行的图编译器。 </td>
  </tr>
  <tr>
    <td><a href="get_npu_backend.md">get_npu_backend</a></td>
    <td>获取能够在NPU上运行的图编译后端npu_backend，可作为backend参数传入torch.compile。 </td>
  </tr>
  <tr>
    <td><a href="use_internal_format_weight.md">use_internal_format_weight</a></td>
    <td>将模型中的权重weight转成TorchAir定义的内部私有格式。 </td>
  </tr>
  <tr>
    <td><a href="register_fx_node_ge_converter.md">register_fx_node_ge_converter</a></td>
    <td>将自定义算子注册到TorchAir框架中。 </td>
  </tr>
  <tr>
    <td><a href="patch_for_hcom.md">patch_for_hcom</a></td>
    <td>针对PyTorch 2.1版本中不支持入图的集合通信算子提供的补丁函数，实现部分集合通信算子入图。 </td>
  </tr>
  <tr>
    <td><a href="register_replacement.md">register_replacement</a></td>
    <td>将自定义算子融合规则注册到TorchAir中，在FX图编译后对图进行算子融合优化。 </td>
  </tr>
  <tr>
    <td rowspan="8">torchair.ge</td>
    <td><a href="DataType类.md">DataType类</a></td>
    <td>将自定义算子融合规则注册到TorchAir中，在FX图编译后对图进行算子融合优化。 </td>
  </tr>
  <tr>
    <td><a href="Format类.md">Format类</a></td>
    <td>数据格式的枚举类，提供了GE的data format定义，方便实现converter函数时调用。 </td>
  </tr>
  <tr>
    <td><a href="Tensor类.md">Tensor类</a></td>
    <td>提供Tensor定义，用于算子入图的converter函数入参类型声明。 </td>
  </tr>
  <tr>
    <td><a href="TensorSpec类.md">TensorSpec类</a></td>
    <td>提供TensorSpec定义，表示算子在Meta推导过程中得到的性能，当前用于算子入图的converter函数入参类型声明。 </td>
  </tr>  
  <tr>
    <td><a href="Const.md">Const</a></td>
    <td>算子converter中的构图元素，表示一个Const节点，即图中的常量值。 </td>
  </tr>  
  <tr>
    <td><a href="Cast.md">Cast</a></td>
    <td>算子converter中的构图元素，表示一个Cast节点，即图中Tensor的类型转换方法。 </td>
  </tr>  
  <tr>
    <td><a href="Clone.md">Clone</a></td>
    <td>算子Converter中的构图元素，表示一个Clone节点，该节点可实现图上任意单个Tensor的拷贝。</td>
  </tr>  
  <tr>
    <td><a href="custom_op.md">custom_op</a></td>
    <td>基于算子原型（IR）实现算子converter函数，完成PyTorch IR与GE IR的转换，方便自定义算子入图。 </td>
  </tr>  
  <tr>
    <td rowspan="3">torchair.inference</td>
    <td><a href="cache_compile.md">cache_compile</a></td>
    <td>aclgraph场景下调用该接口实现模型编译缓存。 </td>
  </tr>
  <tr>
    <td><a href="readable_cache.md">readable_cache</a></td>
    <td>aclgraph场景下调用该接口读取封装的func函数缓存文件compiled_module，并以可读文件（格式不限，如py、txt）格式呈现。 </td>
  </tr>
  <tr>
    <td><a href="set_dim_gears.md">set_dim_gears</a></td>
    <td>调用该接口设置图被划分的档位。 </td>
  </tr>
  <tr>
    <td rowspan="9">torchair.ops</td>
    <td><a href="npu_print.md">npu_print</a></td>
    <td>图执行过程中，打印执行脚本中目标tensor值。 </td>
  </tr>
  <tr>
    <td><a href="npu_fused_infer_attention_score.md">npu_fused_infer_attention_score</a></td>
    <td>图模式场景下的FlashAttention算子，既可以支持全量计算场景（PromptFlashAttention），也可支持增量计算场景（IncreFlashAttention）。 </td>
  </tr>
  <tr>
    <td><a href="npu_fused_infer_attention_score_v2.md">npu_fused_infer_attention_score_v2</a></td>
    <td>图模式场景下的增强版FlashAttention算子，支持全量和增量计算场景。 </td>
  </tr>
  <tr>
    <td><a href="npu_create_tagged_event.md">npu_create_tagged_event</a></td>
    <td>根据tag创建一个唯一的事件对象torch.npu.Event（torch.cuda.Event的NPU形式）用于协调NPU上不同stream之间的同步操作。 </td>
  </tr>
  <tr>
    <td><a href="npu_tagged_event_record.md">npu_tagged_event_record</a></td>
    <td>与torch.npu.Event.record方法类似（torch.cuda.Event.record的NPU形式），用于记录当前流中的事件。 </td>
  </tr>
  <tr>
    <td><a href=npu_tagged_event_wait.md">npu_tagged_event_wait</a></td>
    <td>与torch.npu.Event.wait方法类似（torch.cuda.Event.wait的NPU形式），用于让当前流等待指定的事件完成。</td>
  </tr>
  <tr>
    <td><a href="npu_record_tagged_stream.md">npu_record_tagged_stream</a></td>
    <td>与PyTorch原生torch.Tensor.record_stream接口类似，用于确保张量在特定NPU流完成之前不会被释放。 </td>
  </tr>
  <tr>
    <td><a href="record.md">record</a></td>
    <td>用于显式地在当前Stream上下发一个任务，其返回值可以被torchair.ops.wait等待。。 </td>
  </tr>
  <tr>
    <td><a href="wait.md">wait</a></td>
    <td>用于在多流间控制时序关系，torchair.ops.wait表示当前流需要在传入的tensor对应的节点执行结束后，再继续执行。 </td>
  </tr>
  <tr>
    <td rowspan="5">torchair.scope</td>
    <td><a href="npu_stream_switch.md">npu_stream_switch</a></td>
    <td>图执行过程中，指定图内多个算子分发到不同stream做并行计算。 </td>
  </tr>
  <tr>
    <td><a href="npu_wait_tensor.md">npu_wait_tensor</a></td>
    <td>图执行过程中，控制图内多stream并行计算时序。 </td>
  </tr>
  <tr>
    <td><a href="super_kernel.md">Cast</a></td>
    <td>图执行过程中，标记图内能融合为SuperKernel的上下文算子范围。 </td>
  </tr>
  <tr>
    <td><a href="limit_core_num.md">limit_core_num</a></td>
    <td>图执行过程中，指定图内范围内的算子执行时的AI Core数和Vector Core数。 </td>
  </tr>
  <tr>
    <td><a href="op_never_timeout.md">op_never_timeout</a></td>
    <td>针对GE图中算子添加_op_exec_never_timeout属性，即配置算子不超时，使其不参与超时检测。 </td>
  </tr>
  <tr>
    <td>torchair.llm_datadist</td>
    <td><a href="create_npu_tensors.md">create_npu_tensors</a></td>
    <td>通过一串Device地址创建PyTorch在NPU上的Tensors。主要用于创建大模型中的KV Cache Tensors，所有KV Cache的shape和dtype都一致。 </td>
  </tr>
</tbody>
</table>
