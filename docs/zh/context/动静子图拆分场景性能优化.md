# 动静子图拆分场景性能优化

## 功能简介

动态图模式下，图中存在部分算子能够聚合成静态子图，如N个算子聚合成一个静态子图后只需要一次下发。静态子图中的算子数量对性能影响有如下特点：

-   静态子图中算子数量越多，单次图下发、图执行耗时越长。
-   静态子图中算子数量越多，相较于静态子图中单个算子分别下发，节省的执行时间越多。
-   静态子图中算子数量越多，算子间融合的可能性越大，获得更高执行性能的可能性越大。

综上特点，静态子图中算子数量并非越多越好，而是下发与执行的耗时相互抵消才能达到最好的执行性能。因此针对不同的网络，TorchAir提供了动态图模式中允许设置静态子图算子个数的功能，帮助用户在动态图场景下进行算子性能调优。

## 使用约束

本功能仅支持max-autotune模式。

## 使用方法

该功能通过[torchair.get\_npu\_backend](get_npu_backend.md)中compiler\_config配置，示例如下，仅供参考不支持直接拷贝运行，参数介绍参见下表。

```python
import torch_npu
import torchair
config = torchair.CompilerConfig()
# 在动态图中设置静态子图算子个数
config.experimental_config.static_model_ops_lower_limit= 4
npu_backend = torchair.get_npu_backend(compiler_config=config)
opt_model = torch.compile(model, backend=npu_backend)
```

**表 1**  参数说明


| 参数名 | 说明 |
| --- | --- |
| static_model_ops_lower_limit | 在动态图中设置静态子图算子个数，取值为整型，取值范围为[-1, int64的最大值]（不含0和1）。若不设置则使用GE的默认值。<br>- 当取值为-1：所有算子采用动态执行。<br>- 当取值为0（不支持）：静态子图中的算子数小于0，不存在此场景。<br>- 当取值为1（不支持）：静态子图中的算子数小于1，不存在此场景。<br>- 当取值大于1（例如取值为4）：静态子图中的算子数小于4，静态子图中的算子会在动态图中被动态地下发执行。静态子图中的算子数大于等于4，静态子图中的算子会被转为静态子图统一下发执行。<br>    - 静态子图中的算子数小于4，静态子图中的算子会在动态图中被动态地下发执行。<br>    - 静态子图中的算子数大于等于4，静态子图中的算子会被转为静态子图统一下发执行。 |

