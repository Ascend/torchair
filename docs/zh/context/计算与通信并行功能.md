# 计算与通信并行功能

## 功能简介

大模型切分部署场景中，通过对网络中AllReduce通信算子以及上下文中可以连续切分的算子切分，从而使能通信和计算并行运行，从而达到加速分布式推理的目的。

## 使用约束

-   本功能仅支持max-autotune模式。
-   只有网络中存在通信算子才能切分，切分时，仅对AllReduce通信算子进行切分。

## 使用方法

该功能通过[torchair.get\_npu\_backend](get_npu_backend.md)中compiler\_config配置，示例如下，仅供参考不支持直接拷贝运行，参数说明如下表。

```python
import torch_npu, torchair
config = torchair.CompilerConfig()
# 计算与通信并行开关
config.experimental_config.cc_parallel_enable = True
npu_backend = torchair.get_npu_backend(compiler_config=config)
opt_model = torch.compile(model, backend=npu_backend)
```

**表 1**  参数说明


| 参数名 | 说明 |
| --- | --- |
| cc_parallel_enable | 图执行时是否开启计算与通信并行。<br>- False（默认值）：不开启并行模式。<br>- True：开启并行模式。 |

