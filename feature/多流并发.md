# 特性简介
在NPU芯片上存在多种硬件资源，不同硬件资源之间可以并发执行来最大化芯片的资源利用率，从而提升模型端到端性能。多流并发主要面向以下两种场景：
* 计算/通信并行： 通信算子主要利用SDMA资源进行数据搬运，与计算算子使用的aicore资源独立，可以将计算/通信任务排布到不同流，实现overlap。
* Cube/Vector并行： NPU的A3芯片是CV 分离架构，因此在没有数据依赖时，可以将cube/vector任务排布到不同流，实现overlap。

如大模型推理中，moe模块的共享专家和路由专家无数据依赖，可以用路有专家的gating计算和dispatch通信 去掩盖共享专家的cube计算，缩短推理的总耗时。


# 特性说明
Torchair 提供了对外的 API 方便用户在脚本中，直接在网络模型中将串行任务拆解，基于多流完成并发的任务编排。

 **对外接口说明：** 

```
def npu_stream_switch(stream_tag: str, stream_priority: int = 0):
    """
    创建一个在指定stream上执行的context manager

    Args:
        stream_tag: string类型入参，用于指定当前context manager中所使用stream的tag
        stream_priority: 预留参数，int类型入参，默认值0，用于指定当前context manager中所使用stream的优先级
        
    Returns:
        返回基于用户入参创建的stream的context manager
    """
```

 **接口调用说明：** 
* 可以在多次调用 `npu_stream_switch` 时传入相同的 `stream_tag`，此时表示创建的多个 `context manager` 都在相同的 `stream_tag` 流上执行。
* 调用 `npu_stream_switch` 创建 `context manager` 时支持嵌套使用。


# 使用示例
使用前面的多流 API，构造一个示例模型，包含两组cube/vector并发。


```
import torch, torch_npu, torchair


"""
  示例模型并发点：
  s0_add1 在默认stream执行，s1_mm  在流“1”执行，这部分双流并发。
  s0_mm1  在默认stream执行，s2_add 在流“2”执行，这部分双流并发。
"""
class Model(torch.nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, in1, in2, in3):
        s0_add1 = torch.add(in1, in2)
        with torchair.scope.npu_stream_switch('1'):
            s1_mm = torch.mm(in1, in2)

        s0_mm1 = torch.mm(in3, s0_add1)
        with torchair.scope.npu_stream_switch('2'):
            s2_add = torch.add(in3, s1_mm)
        return s0_mm1, s2_add

model = Model()
npu_backend = torchair.get_npu_backend()
model = torch.compile(model, backend=npu_backend, dynamic=False, fullgraph=True)

in1 = torch.randn(1000, 1000, dtype=torch.float16).npu()
in2 = torch.randn(1000, 1000, dtype=torch.float16).npu()
in3 = torch.randn(1000, 1000, dtype=torch.float16).npu()
result = model(in1, in2, in3)
print(f"Result:\n{result}\n")

```

